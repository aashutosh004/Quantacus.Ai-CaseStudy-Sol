{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6c070fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb12763a",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_opened = pd.read_csv(\"email_opened_table.csv\")\n",
    "email_table = pd.read_csv(\"email_table.csv\")\n",
    "link_clicked = pd.read_csv(\"link_clicked_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f127d7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not email_opened['email_id'].isin(email_table['email_id']).all():\n",
    "    print(\"Warning: Some email_ids in email_opened_table not found in email_table\")\n",
    "if not link_clicked['email_id'].isin(email_table['email_id']).all():\n",
    "    print(\"Warning: Some email_ids in link_clicked_table not found in email_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4913217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in email_table:\n",
      " email_id               0\n",
      "email_text             0\n",
      "email_version          0\n",
      "hour                   0\n",
      "weekday                0\n",
      "user_country           0\n",
      "user_past_purchases    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in email_opened:\n",
      " email_id    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in link_clicked:\n",
      " email_id    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing values in email_table:\\n\", email_table.isnull().sum())\n",
    "print(\"\\nMissing values in email_opened:\\n\", email_opened.isnull().sum())\n",
    "print(\"\\nMissing values in link_clicked:\\n\", link_clicked.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ddb6dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_table['opened'] = email_table['email_id'].isin(email_opened['email_id']).astype(int)\n",
    "email_table['clicked'] = email_table['email_id'].isin(link_clicked['email_id']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "022d35e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Emails Sent: 100000\n",
      "Emails Opened: 10345\n",
      "Emails Clicked: 2119\n",
      "Open Rate: 10.35%\n",
      "Click-Through Rate: 2.12%\n"
     ]
    }
   ],
   "source": [
    "total_emails = len(email_table)\n",
    "emails_opened = email_table['opened'].sum()\n",
    "emails_clicked = email_table['clicked'].sum()\n",
    "open_rate = (emails_opened / total_emails) * 100\n",
    "ctr = (emails_clicked / total_emails) * 100\n",
    "\n",
    "print(f\"\\nTotal Emails Sent: {total_emails}\")\n",
    "print(f\"Emails Opened: {emails_opened}\")\n",
    "print(f\"Emails Clicked: {emails_clicked}\")\n",
    "print(f\"Open Rate: {open_rate:.2f}%\")\n",
    "print(f\"Click-Through Rate: {ctr:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e449116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar(feature, target):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=feature, y=target, data=email_table)\n",
    "    plt.title(f'{target.capitalize()} Rate by {feature.capitalize()}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.savefig(f'{target}_by_{feature}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b70f0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_plot = ['email_text', 'email_version', 'user_country', 'weekday', 'user_past_purchases']\n",
    "for feature in features_to_plot:\n",
    "    plot_bar(feature, 'opened')\n",
    "    plot_bar(feature, 'clicked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c55ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_table['hour'] = email_table['hour'].astype(int)\n",
    "plot_bar('hour', 'opened')\n",
    "plot_bar('hour', 'clicked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f470a402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Click Rate by Segment:\n",
      "\n",
      "email_text:\n",
      "email_text\n",
      "long_email     1.853767\n",
      "short_email    2.387177\n",
      "Name: clicked, dtype: float64\n",
      "\n",
      "email_version:\n",
      "email_version\n",
      "generic         1.513673\n",
      "personalized    2.729409\n",
      "Name: clicked, dtype: float64\n",
      "\n",
      "user_country:\n",
      "user_country\n",
      "ES    0.832748\n",
      "FR    0.800400\n",
      "UK    2.467526\n",
      "US    2.435981\n",
      "Name: clicked, dtype: float64\n",
      "\n",
      "weekday:\n",
      "weekday\n",
      "Friday       1.403682\n",
      "Monday       2.290608\n",
      "Saturday     1.784611\n",
      "Sunday       1.675123\n",
      "Thursday     2.444491\n",
      "Tuesday      2.488864\n",
      "Wednesday    2.761999\n",
      "Name: clicked, dtype: float64\n",
      "\n",
      "user_past_purchases:\n",
      "user_past_purchases\n",
      "0       0.050443\n",
      "1       1.119919\n",
      "2       1.534213\n",
      "3       1.656040\n",
      "4       2.140929\n",
      "5       2.222960\n",
      "6       3.205640\n",
      "7       3.073872\n",
      "8       3.960847\n",
      "9       4.550971\n",
      "10      4.655099\n",
      "11      5.602061\n",
      "12      6.567797\n",
      "13      6.574394\n",
      "14      9.116022\n",
      "15     11.702128\n",
      "16     11.764706\n",
      "17      8.333333\n",
      "18      2.857143\n",
      "19     20.000000\n",
      "20      0.000000\n",
      "21     50.000000\n",
      "22    100.000000\n",
      "Name: clicked, dtype: float64\n",
      "\n",
      "hour:\n",
      "hour\n",
      "1     1.812801\n",
      "2     1.632209\n",
      "3     1.952278\n",
      "4     1.618641\n",
      "5     1.801252\n",
      "6     1.714668\n",
      "7     1.828376\n",
      "8     1.893308\n",
      "9     2.579435\n",
      "10    2.823961\n",
      "11    2.712816\n",
      "12    2.566073\n",
      "13    1.988891\n",
      "14    2.074236\n",
      "15    2.490696\n",
      "16    2.319681\n",
      "17    1.848917\n",
      "18    1.618578\n",
      "19    1.657459\n",
      "20    1.219512\n",
      "21    0.821918\n",
      "22    1.960784\n",
      "23    4.137931\n",
      "24    2.898551\n",
      "Name: clicked, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClick Rate by Segment:\")\n",
    "for feature in features_to_plot + ['hour']:\n",
    "    print(f\"\\n{feature}:\")\n",
    "    print(email_table.groupby(feature)['clicked'].mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89601415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Click Rate by Email Version and Country:\n",
      "user_country         ES        FR        UK        US\n",
      "email_version                                        \n",
      "generic        0.562588  0.536459  1.826209  1.729898\n",
      "personalized   1.102204  1.068118  3.108393  3.150740\n"
     ]
    }
   ],
   "source": [
    "pivot = email_table.pivot_table(values='clicked', index='email_version', columns='user_country', aggfunc='mean') * 100\n",
    "print(\"\\nClick Rate by Email Version and Country:\")\n",
    "print(pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80cb33f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Key Patterns:\n",
      "- Short emails had higher click rates than long emails.\n",
      "- Personalized emails outperformed generic ones, especially in the US and UK.\n",
      "- Users with more past purchases (5+) had higher click rates.\n",
      "- Emails sent on weekdays, particularly Wednesday, had higher click rates than weekends.\n",
      "- Emails sent in the morning (8-11 AM) had higher open and click rates.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nKey Patterns:\")\n",
    "print(\"- Short emails had higher click rates than long emails.\")\n",
    "print(\"- Personalized emails outperformed generic ones, especially in the US and UK.\")\n",
    "print(\"- Users with more past purchases (5+) had higher click rates.\")\n",
    "print(\"- Emails sent on weekdays, particularly Wednesday, had higher click rates than weekends.\")\n",
    "print(\"- Emails sent in the morning (8-11 AM) had higher open and click rates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4bf1183",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_text = LabelEncoder()\n",
    "email_table['email_text'] = label_encoder_text.fit_transform(email_table['email_text'])\n",
    "label_encoder_version = LabelEncoder()\n",
    "email_table['email_version'] = label_encoder_version.fit_transform(email_table['email_version'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa92192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder_country = OneHotEncoder(sparse_output=False)\n",
    "country_encoded = onehot_encoder_country.fit_transform(email_table[['user_country']])\n",
    "country_encoded_df = pd.DataFrame(\n",
    "    country_encoded,\n",
    "    columns=onehot_encoder_country.get_feature_names_out(['user_country'])\n",
    ").astype(int)\n",
    "email_table = pd.concat([email_table.drop(['user_country'], axis=1), country_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9f334a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder_weekday = OneHotEncoder(sparse_output=False)\n",
    "weekday_encoded = onehot_encoder_weekday.fit_transform(email_table[['weekday']])\n",
    "weekday_encoded_df = pd.DataFrame(\n",
    "    weekday_encoded,\n",
    "    columns=onehot_encoder_weekday.get_feature_names_out(['weekday'])\n",
    ").astype(int)\n",
    "email_table = pd.concat([email_table.drop(['weekday'], axis=1), weekday_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad5fe99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_table['hour_bin'] = pd.cut(\n",
    "    email_table['hour'],\n",
    "    bins=[0, 6, 12, 18, 24],\n",
    "    labels=['Night', 'Morning', 'Afternoon', 'Evening'],\n",
    "    include_lowest=True\n",
    ")\n",
    "plot_bar('hour_bin', 'opened')\n",
    "plot_bar('hour_bin', 'clicked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8ea6c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder_hour_bin = OneHotEncoder(sparse_output=False)\n",
    "hour_bin_encoded = onehot_encoder_hour_bin.fit_transform(email_table[['hour_bin']])\n",
    "hour_bin_encoded_df = pd.DataFrame(\n",
    "    hour_bin_encoded,\n",
    "    columns=onehot_encoder_hour_bin.get_feature_names_out(['hour_bin'])\n",
    ").astype(int)\n",
    "email_table = pd.concat([email_table.drop(['hour', 'hour_bin'], axis=1), hour_bin_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48d35c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = email_table.drop(['email_id', 'opened', 'clicked'], axis=1)\n",
    "y = email_table['clicked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "977990e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c86ddf80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=15, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=15, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=15, random_state=42)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11b1374a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance:\n",
      "Accuracy: 0.79\n",
      "AUC-ROC: 0.69\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.80      0.88     19576\n",
      "           1       0.04      0.40      0.08       424\n",
      "\n",
      "    accuracy                           0.79     20000\n",
      "   macro avg       0.51      0.60      0.48     20000\n",
      "weighted avg       0.96      0.79      0.87     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"AUC-ROC: {auc:.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50f9a0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance:\n",
      "                feature  importance\n",
      "2   user_past_purchases    0.561124\n",
      "1         email_version    0.065198\n",
      "0            email_text    0.057236\n",
      "4       user_country_FR    0.027987\n",
      "3       user_country_ES    0.026012\n",
      "16     hour_bin_Morning    0.024984\n",
      "17       hour_bin_Night    0.023244\n",
      "6       user_country_US    0.022945\n",
      "14   hour_bin_Afternoon    0.022798\n",
      "5       user_country_UK    0.021338\n",
      "7        weekday_Friday    0.019998\n",
      "9      weekday_Saturday    0.019948\n",
      "10       weekday_Sunday    0.019674\n",
      "12      weekday_Tuesday    0.019618\n",
      "8        weekday_Monday    0.019450\n",
      "13    weekday_Wednesday    0.019310\n",
      "11     weekday_Thursday    0.018325\n",
      "15     hour_bin_Evening    0.010811\n"
     ]
    }
   ],
   "source": [
    "# Feature importance\n",
    "importances = pd.DataFrame({'feature': X.columns, 'importance': model.feature_importances_})\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(importances.sort_values(by='importance', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "902ed425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CTR Estimation:\n",
      "Baseline CTR: 2.12%\n",
      "Model CTR (targeting top 100000 users): 2.12%\n",
      "CTR Improvement: 0.00%\n",
      "Testing Method: Conduct A/B testing by sending emails to a model-targeted group (high-probability users) and a random group, then compare CTRs.\n"
     ]
    }
   ],
   "source": [
    "# Simulate targeting top users based on predicted probabilities\n",
    "test_results = pd.DataFrame({'prob': y_prob, 'clicked': y_test})\n",
    "test_results = test_results.sort_values(by='prob', ascending=False)\n",
    "N = len(email_table)  # Total emails sent\n",
    "top_n = test_results.head(N)\n",
    "new_ctr = top_n['clicked'].mean() * 100\n",
    "\n",
    "print(f\"\\nCTR Estimation:\")\n",
    "print(f\"Baseline CTR: {ctr:.2f}%\")\n",
    "print(f\"Model CTR (targeting top {N} users): {new_ctr:.2f}%\")\n",
    "print(f\"CTR Improvement: {new_ctr - ctr:.2f}%\")\n",
    "print(\"Testing Method: Conduct A/B testing by sending emails to a model-targeted group (high-probability users) and a random group, then compare CTRs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba75cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirement 2: Build Machine Learning Model\n",
    "# Preprocess data\n",
    "# Label encode email_text and email_version\n",
    "\n",
    "\n",
    "# One-hot encode user_country\n",
    "\n",
    "\n",
    "# One-hot encode weekday\n",
    "\n",
    "\n",
    "# Create hour_bin and one-hot encode\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Prepare features and target\n",
    "\n",
    "\n",
    "# Split data\n",
    "\n",
    "\n",
    "# Train Random Forest model with class weighting\n",
    "\n",
    "\n",
    "# Predict and evaluate\n",
    "\n",
    "\n",
    "# Requirement 3: Estimate CTR Improvement\n",
    "\n",
    "\n",
    "# Save final dataset for reference\n",
    "email_table.to_csv('processed_email_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab75d255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87ef447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16d6f28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in email_table:\n",
      " email_id               0\n",
      "email_text             0\n",
      "email_version          0\n",
      "hour                   0\n",
      "weekday                0\n",
      "user_country           0\n",
      "user_past_purchases    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in email_opened:\n",
      " email_id    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in link_clicked:\n",
      " email_id    0\n",
      "dtype: int64\n",
      "\n",
      "Total Emails Sent: 100000\n",
      "Emails Opened: 10345\n",
      "Emails Clicked: 2119\n",
      "Open Rate: 10.35%\n",
      "Click-Through Rate: 2.12%\n",
      "\n",
      "Click Rate by Segment:\n",
      "\n",
      "email_text:\n",
      "email_text\n",
      "long_email     1.853767\n",
      "short_email    2.387177\n",
      "Name: clicked, dtype: float64\n",
      "\n",
      "email_version:\n",
      "email_version\n",
      "generic         1.513673\n",
      "personalized    2.729409\n",
      "Name: clicked, dtype: float64\n",
      "\n",
      "user_country:\n",
      "user_country\n",
      "ES    0.832748\n",
      "FR    0.800400\n",
      "UK    2.467526\n",
      "US    2.435981\n",
      "Name: clicked, dtype: float64\n",
      "\n",
      "weekday:\n",
      "weekday\n",
      "Friday       1.403682\n",
      "Monday       2.290608\n",
      "Saturday     1.784611\n",
      "Sunday       1.675123\n",
      "Thursday     2.444491\n",
      "Tuesday      2.488864\n",
      "Wednesday    2.761999\n",
      "Name: clicked, dtype: float64\n",
      "\n",
      "user_past_purchases:\n",
      "user_past_purchases\n",
      "0       0.050443\n",
      "1       1.119919\n",
      "2       1.534213\n",
      "3       1.656040\n",
      "4       2.140929\n",
      "5       2.222960\n",
      "6       3.205640\n",
      "7       3.073872\n",
      "8       3.960847\n",
      "9       4.550971\n",
      "10      4.655099\n",
      "11      5.602061\n",
      "12      6.567797\n",
      "13      6.574394\n",
      "14      9.116022\n",
      "15     11.702128\n",
      "16     11.764706\n",
      "17      8.333333\n",
      "18      2.857143\n",
      "19     20.000000\n",
      "20      0.000000\n",
      "21     50.000000\n",
      "22    100.000000\n",
      "Name: clicked, dtype: float64\n",
      "\n",
      "hour:\n",
      "hour\n",
      "1     1.812801\n",
      "2     1.632209\n",
      "3     1.952278\n",
      "4     1.618641\n",
      "5     1.801252\n",
      "6     1.714668\n",
      "7     1.828376\n",
      "8     1.893308\n",
      "9     2.579435\n",
      "10    2.823961\n",
      "11    2.712816\n",
      "12    2.566073\n",
      "13    1.988891\n",
      "14    2.074236\n",
      "15    2.490696\n",
      "16    2.319681\n",
      "17    1.848917\n",
      "18    1.618578\n",
      "19    1.657459\n",
      "20    1.219512\n",
      "21    0.821918\n",
      "22    1.960784\n",
      "23    4.137931\n",
      "24    2.898551\n",
      "Name: clicked, dtype: float64\n",
      "\n",
      "Click Rate by Email Version and Country:\n",
      "user_country         ES        FR        UK        US\n",
      "email_version                                        \n",
      "generic        0.562588  0.536459  1.826209  1.729898\n",
      "personalized   1.102204  1.068118  3.108393  3.150740\n",
      "\n",
      "Chi-Square Test (email_version vs. clicked): p-value = 0.0000\n",
      "\n",
      "Key Patterns (Based on Data Analysis):\n",
      "- Short emails had a 2.39% click rate, compared to 1.85% for long emails.\n",
      "- Personalized emails had a 2.73% click rate, significantly higher than 1.51% for generic emails (p < 0.0001).\n",
      "- Users in the US (2.44%) and UK (2.47%) had higher click rates than those in ES (0.83%) and FR (0.80%).\n",
      "- Users with 5+ past purchases had click rates above 3%, with 15 purchases at 11.70% and 19 at 20.00%.\n",
      "- Emails sent on Wednesdays (2.76%) and in the morning (9-11 AM: 2.58-2.82%) had the highest click rates.\n",
      "\n",
      "Class Imbalance in Target (clicked):\n",
      "   Class  Count  Percentage\n",
      "0      0  97881      97.881\n",
      "1      1   2119       2.119\n",
      "\n",
      "F1-Optimal Threshold: 0.773\n",
      "\n",
      "Model Performance (F1-Optimal Threshold):\n",
      "Accuracy: 0.95\n",
      "AUC-ROC: 0.67\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97     19576\n",
      "           1       0.08      0.15      0.11       424\n",
      "\n",
      "    accuracy                           0.95     20000\n",
      "   macro avg       0.53      0.56      0.54     20000\n",
      "weighted avg       0.96      0.95      0.95     20000\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "                       feature  importance\n",
      "19  user_past_purchases_scaled    0.189880\n",
      "3              user_country_FR    0.068019\n",
      "5              user_country_US    0.062286\n",
      "2              user_country_ES    0.057453\n",
      "15            hour_bin_Morning    0.056447\n",
      "13          hour_bin_Afternoon    0.054638\n",
      "14            hour_bin_Evening    0.048981\n",
      "4              user_country_UK    0.047490\n",
      "8             weekday_Saturday    0.042218\n",
      "9               weekday_Sunday    0.042156\n",
      "18          version_country_UK    0.042155\n",
      "6               weekday_Friday    0.041655\n",
      "7               weekday_Monday    0.037609\n",
      "11             weekday_Tuesday    0.035789\n",
      "12           weekday_Wednesday    0.035440\n",
      "16              hour_bin_Night    0.030729\n",
      "17          version_country_US    0.030186\n",
      "10            weekday_Thursday    0.029130\n",
      "1                email_version    0.026675\n",
      "0                   email_text    0.021067\n",
      "\n",
      "CTR Estimation:\n",
      "Baseline CTR: 2.12%\n",
      "Model CTR (F1-Optimal Threshold 0.773, top 20000 users): 8.18%\n",
      "CTR Improvement (F1-Optimal): 6.07%\n",
      "Model CTR (80th Percentile Threshold 0.555, top 20000 users): 3.98%\n",
      "CTR Improvement (80th Percentile): 1.86%\n",
      "Testing Method: Conduct A/B testing by sending emails to a model-targeted group (high-probability users) and a random group, then compare CTRs.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.combine import SMOTEENN\n",
    "from scipy.stats import chi2_contingency\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Function to plot bar charts\n",
    "def plot_bar(feature, target, data, save=True):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=feature, y=target, data=data)\n",
    "    plt.title(f'{target.capitalize()} Rate by {feature.capitalize()}')\n",
    "    plt.xticks(rotation=45)\n",
    "    if save:\n",
    "        plt.savefig(f'{target}_by_{feature}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Load data with error handling\n",
    "try:\n",
    "    email_opened = pd.read_csv(\"email_opened_table.csv\")\n",
    "    email_table = pd.read_csv(\"email_table.csv\")\n",
    "    link_clicked = pd.read_csv(\"link_clicked_table.csv\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}. Please ensure CSV files are in the working directory.\")\n",
    "    exit(1)\n",
    "\n",
    "# Data validation\n",
    "if not email_opened['email_id'].isin(email_table['email_id']).all():\n",
    "    print(\"Warning: Some email_ids in email_opened_table not found in email_table\")\n",
    "if not link_clicked['email_id'].isin(email_table['email_id']).all():\n",
    "    print(\"Warning: Some email_ids in link_clicked_table not found in email_table\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in email_table:\\n\", email_table.isnull().sum())\n",
    "print(\"\\nMissing values in email_opened:\\n\", email_opened.isnull().sum())\n",
    "print(\"\\nMissing values in link_clicked:\\n\", link_clicked.isnull().sum())\n",
    "\n",
    "# Add opened and clicked columns\n",
    "email_table['opened'] = email_table['email_id'].isin(email_opened['email_id']).astype(int)\n",
    "email_table['clicked'] = email_table['email_id'].isin(link_clicked['email_id']).astype(int)\n",
    "\n",
    "# Requirement 1: Calculate Open Rate and Click-Through Rate\n",
    "total_emails = len(email_table)\n",
    "emails_opened = email_table['opened'].sum()\n",
    "emails_clicked = email_table['clicked'].sum()\n",
    "open_rate = (emails_opened / total_emails) * 100\n",
    "ctr = (emails_clicked / total_emails) * 100\n",
    "\n",
    "print(f\"\\nTotal Emails Sent: {total_emails}\")\n",
    "print(f\"Emails Opened: {emails_opened}\")\n",
    "print(f\"Emails Clicked: {emails_clicked}\")\n",
    "print(f\"Open Rate: {open_rate:.2f}%\")\n",
    "print(f\"Click-Through Rate: {ctr:.2f}%\")\n",
    "\n",
    "# Requirement 4: Identify Patterns (Exploratory Data Analysis)\n",
    "# Plot open and click rates\n",
    "features_to_plot = ['email_text', 'email_version', 'user_country', 'weekday', 'user_past_purchases']\n",
    "for feature in features_to_plot:\n",
    "    plot_bar(feature, 'opened', email_table)\n",
    "    plot_bar(feature, 'clicked', email_table)\n",
    "\n",
    "# Ensure hour is integer and plot\n",
    "email_table['hour'] = email_table['hour'].astype(int)\n",
    "plot_bar('hour', 'opened', email_table)\n",
    "plot_bar('hour', 'clicked', email_table)\n",
    "\n",
    "# Summarize click rates by segment\n",
    "print(\"\\nClick Rate by Segment:\")\n",
    "for feature in features_to_plot + ['hour']:\n",
    "    print(f\"\\n{feature}:\")\n",
    "    print(email_table.groupby(feature)['clicked'].mean() * 100)\n",
    "\n",
    "# Analyze interactions\n",
    "pivot = email_table.pivot_table(values='clicked', index='email_version', columns='user_country', aggfunc='mean') * 100\n",
    "print(\"\\nClick Rate by Email Version and Country:\")\n",
    "print(pivot)\n",
    "\n",
    "# Statistical test for significance (e.g., email_version vs. clicked)\n",
    "contingency_table = pd.crosstab(email_table['email_version'], email_table['clicked'])\n",
    "chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "print(f\"\\nChi-Square Test (email_version vs. clicked): p-value = {p:.4f}\")\n",
    "\n",
    "# Key patterns (specific values from output)\n",
    "print(\"\\nKey Patterns (Based on Data Analysis):\")\n",
    "print(\"- Short emails had a 2.39% click rate, compared to 1.85% for long emails.\")\n",
    "print(\"- Personalized emails had a 2.73% click rate, significantly higher than 1.51% for generic emails (p < 0.0001).\")\n",
    "print(\"- Users in the US (2.44%) and UK (2.47%) had higher click rates than those in ES (0.83%) and FR (0.80%).\")\n",
    "print(\"- Users with 5+ past purchases had click rates above 3%, with 15 purchases at 11.70% and 19 at 20.00%.\")\n",
    "print(\"- Emails sent on Wednesdays (2.76%) and in the morning (9-11 AM: 2.58-2.82%) had the highest click rates.\")\n",
    "\n",
    "# Requirement 2: Build Machine Learning Model\n",
    "# Preprocess data\n",
    "label_encoder_text = LabelEncoder()\n",
    "email_table['email_text'] = label_encoder_text.fit_transform(email_table['email_text'])\n",
    "label_encoder_version = LabelEncoder()\n",
    "email_table['email_version'] = label_encoder_version.fit_transform(email_table['email_version'])\n",
    "\n",
    "# One-hot encode user_country\n",
    "onehot_encoder_country = OneHotEncoder(sparse_output=False)\n",
    "country_encoded = onehot_encoder_country.fit_transform(email_table[['user_country']])\n",
    "country_encoded_df = pd.DataFrame(\n",
    "    country_encoded,\n",
    "    columns=onehot_encoder_country.get_feature_names_out(['user_country'])\n",
    ").astype(int)\n",
    "email_table = pd.concat([email_table.drop(['user_country'], axis=1), country_encoded_df], axis=1)\n",
    "\n",
    "# One-hot encode weekday\n",
    "onehot_encoder_weekday = OneHotEncoder(sparse_output=False)\n",
    "weekday_encoded = onehot_encoder_weekday.fit_transform(email_table[['weekday']])\n",
    "weekday_encoded_df = pd.DataFrame(\n",
    "    weekday_encoded,\n",
    "    columns=onehot_encoder_weekday.get_feature_names_out(['weekday'])\n",
    ").astype(int)\n",
    "email_table = pd.concat([email_table.drop(['weekday'], axis=1), weekday_encoded_df], axis=1)\n",
    "\n",
    "# Create and encode hour_bin\n",
    "email_table['hour_bin'] = pd.cut(\n",
    "    email_table['hour'],\n",
    "    bins=[0, 6, 12, 18, 24],\n",
    "    labels=['Night', 'Morning', 'Afternoon', 'Evening'],\n",
    "    include_lowest=True\n",
    ")\n",
    "plot_bar('hour_bin', 'opened', email_table)\n",
    "plot_bar('hour_bin', 'clicked', email_table)\n",
    "\n",
    "onehot_encoder_hour_bin = OneHotEncoder(sparse_output=False)\n",
    "hour_bin_encoded = onehot_encoder_hour_bin.fit_transform(email_table[['hour_bin']])\n",
    "hour_bin_encoded_df = pd.DataFrame(\n",
    "    hour_bin_encoded,\n",
    "    columns=onehot_encoder_hour_bin.get_feature_names_out(['hour_bin'])\n",
    ").astype(int)\n",
    "email_table = pd.concat([email_table.drop(['hour', 'hour_bin'], axis=1), hour_bin_encoded_df], axis=1)\n",
    "\n",
    "# Feature engineering: Add interaction terms\n",
    "email_table['version_country_US'] = email_table['email_version'] * email_table['user_country_US']\n",
    "email_table['version_country_UK'] = email_table['email_version'] * email_table['user_country_UK']\n",
    "\n",
    "# Scale user_past_purchases\n",
    "scaler = StandardScaler()\n",
    "email_table['user_past_purchases_scaled'] = scaler.fit_transform(email_table[['user_past_purchases']])\n",
    "\n",
    "# Prepare features and target\n",
    "X = email_table.drop(['email_id', 'opened', 'clicked', 'user_past_purchases'], axis=1)  # Use scaled purchases\n",
    "y = email_table['clicked']\n",
    "\n",
    "# Check class imbalance\n",
    "print(\"\\nClass Imbalance in Target (clicked):\")\n",
    "class_counts = pd.Series(y).value_counts()\n",
    "class_percentages = pd.Series(y).value_counts(normalize=True) * 100\n",
    "print(pd.DataFrame({\n",
    "    'Class': class_counts.index,\n",
    "    'Count': class_counts.values,\n",
    "    'Percentage': class_percentages.values\n",
    "}))\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply SMOTEENN to balance training data\n",
    "smoteenn = SMOTEENN(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smoteenn.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train XGBoost model\n",
    "model = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=10,  # Reduced to balance precision and recall\n",
    "    eval_metric='aucpr',\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Find F1-optimal threshold\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "optimal_idx = np.argmax(f1_scores)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(f\"\\nF1-Optimal Threshold: {optimal_threshold:.3f}\")\n",
    "\n",
    "# Evaluate with optimal threshold\n",
    "y_pred = (y_prob >= optimal_threshold).astype(int)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "print(f\"\\nModel Performance (F1-Optimal Threshold):\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"AUC-ROC: {auc:.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Precision-Recall Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.axvline(x=recall[optimal_idx], color='r', linestyle='--', label=f'F1-Optimal Threshold ({optimal_threshold:.3f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.savefig('precision_recall_curve.png')\n",
    "plt.close()\n",
    "\n",
    "# Feature importance\n",
    "importances = pd.DataFrame({'feature': X.columns, 'importance': model.feature_importances_})\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(importances.sort_values(by='importance', ascending=False))\n",
    "\n",
    "# Requirement 3: Estimate CTR Improvement\n",
    "# Simulate targeting top 20% of users with F1-optimal threshold\n",
    "N = int(0.2 * len(email_table))  # 20,000 emails\n",
    "test_results = pd.DataFrame({'prob': y_prob, 'clicked': y_test, 'index': X_test.index})\n",
    "high_prob_users = test_results[test_results['prob'] >= optimal_threshold]\n",
    "top_n = high_prob_users.head(N)  # Limit to N users\n",
    "new_ctr_optimal = top_n['clicked'].mean() * 100 if not top_n.empty else 0.0\n",
    "\n",
    "# Also test 80th percentile threshold for comparison\n",
    "threshold_80 = np.percentile(test_results['prob'], 80)\n",
    "high_prob_users_80 = test_results[test_results['prob'] >= threshold_80]\n",
    "top_n_80 = high_prob_users_80.head(N)\n",
    "new_ctr_80 = top_n_80['clicked'].mean() * 100 if not top_n_80.empty else 0.0\n",
    "\n",
    "print(f\"\\nCTR Estimation:\")\n",
    "print(f\"Baseline CTR: {ctr:.2f}%\")\n",
    "print(f\"Model CTR (F1-Optimal Threshold {optimal_threshold:.3f}, top {N} users): {new_ctr_optimal:.2f}%\")\n",
    "print(f\"CTR Improvement (F1-Optimal): {new_ctr_optimal - ctr:.2f}%\")\n",
    "print(f\"Model CTR (80th Percentile Threshold {threshold_80:.3f}, top {N} users): {new_ctr_80:.2f}%\")\n",
    "print(f\"CTR Improvement (80th Percentile): {new_ctr_80 - ctr:.2f}%\")\n",
    "print(\"Testing Method: Conduct A/B testing by sending emails to a model-targeted group (high-probability users) and a random group, then compare CTRs.\")\n",
    "\n",
    "# Save predictions and results\n",
    "test_results.to_csv('model_predictions.csv', index=False)\n",
    "email_table.to_csv('processed_email_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f21798b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in email_table:\n",
      " email_id               0\n",
      "email_text             0\n",
      "email_version          0\n",
      "hour                   0\n",
      "weekday                0\n",
      "user_country           0\n",
      "user_past_purchases    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in email_opened:\n",
      " email_id    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in link_clicked:\n",
      " email_id    0\n",
      "dtype: int64\n",
      "\n",
      "Total Emails Sent: 100000\n",
      "Emails Opened: 10345\n",
      "Emails Clicked: 2119\n",
      "Open Rate: 10.35%\n",
      "Click-Through Rate: 2.12%\n",
      "\n",
      "Click Rate by Segment:\n",
      "\n",
      "email_text:\n",
      "email_text\n",
      "long_email     1.853767\n",
      "short_email    2.387177\n",
      "Name: clicked, dtype: float64\n",
      "\n",
      "email_version:\n",
      "email_version\n",
      "generic         1.513673\n",
      "personalized    2.729409\n",
      "Name: clicked, dtype: float64\n",
      "\n",
      "user_country:\n",
      "user_country\n",
      "ES    0.832748\n",
      "FR    0.800400\n",
      "UK    2.467526\n",
      "US    2.435981\n",
      "Name: clicked, dtype: float64\n",
      "\n",
      "weekday:\n",
      "weekday\n",
      "Friday       1.403682\n",
      "Monday       2.290608\n",
      "Saturday     1.784611\n",
      "Sunday       1.675123\n",
      "Thursday     2.444491\n",
      "Tuesday      2.488864\n",
      "Wednesday    2.761999\n",
      "Name: clicked, dtype: float64\n",
      "\n",
      "user_past_purchases:\n",
      "user_past_purchases\n",
      "0       0.050443\n",
      "1       1.119919\n",
      "2       1.534213\n",
      "3       1.656040\n",
      "4       2.140929\n",
      "5       2.222960\n",
      "6       3.205640\n",
      "7       3.073872\n",
      "8       3.960847\n",
      "9       4.550971\n",
      "10      4.655099\n",
      "11      5.602061\n",
      "12      6.567797\n",
      "13      6.574394\n",
      "14      9.116022\n",
      "15     11.702128\n",
      "16     11.764706\n",
      "17      8.333333\n",
      "18      2.857143\n",
      "19     20.000000\n",
      "20      0.000000\n",
      "21     50.000000\n",
      "22    100.000000\n",
      "Name: clicked, dtype: float64\n",
      "\n",
      "hour:\n",
      "hour\n",
      "1     1.812801\n",
      "2     1.632209\n",
      "3     1.952278\n",
      "4     1.618641\n",
      "5     1.801252\n",
      "6     1.714668\n",
      "7     1.828376\n",
      "8     1.893308\n",
      "9     2.579435\n",
      "10    2.823961\n",
      "11    2.712816\n",
      "12    2.566073\n",
      "13    1.988891\n",
      "14    2.074236\n",
      "15    2.490696\n",
      "16    2.319681\n",
      "17    1.848917\n",
      "18    1.618578\n",
      "19    1.657459\n",
      "20    1.219512\n",
      "21    0.821918\n",
      "22    1.960784\n",
      "23    4.137931\n",
      "24    2.898551\n",
      "Name: clicked, dtype: float64\n",
      "\n",
      "Click Rate by Email Version and Country:\n",
      "user_country         ES        FR        UK        US\n",
      "email_version                                        \n",
      "generic        0.562588  0.536459  1.826209  1.729898\n",
      "personalized   1.102204  1.068118  3.108393  3.150740\n",
      "\n",
      "Chi-Square Test (email_version vs. clicked): p-value = 0.0000\n",
      "\n",
      "Key Patterns (Based on Data Analysis):\n",
      "- Short emails had a 2.39% click rate, compared to 1.85% for long emails.\n",
      "- Personalized emails had a 2.73% click rate, significantly higher than 1.51% for generic emails (p < 0.0001).\n",
      "- Users in the US (2.44%) and UK (2.47%) had higher click rates than those in ES (0.83%) and FR (0.80%).\n",
      "- Users with 5+ past purchases had click rates above 3%, with 15 purchases at 11.70% and 19 at 20.00%.\n",
      "- Emails sent on Wednesdays (2.76%) and in the morning (9-11 AM: 2.58-2.82%) had the highest click rates.\n",
      "\n",
      "Class Imbalance in Target (clicked):\n",
      "   Class  Count  Percentage\n",
      "0      0  97881      97.881\n",
      "1      1   2119       2.119\n",
      "\n",
      "Best Model: Balanced Random Forest\n",
      "F1-Optimal Threshold: 0.709\n",
      "\n",
      "Model Performance (F1-Optimal Threshold):\n",
      "Accuracy: 0.93\n",
      "AUC-ROC: 0.73\n",
      "Cross-Validated AUC-ROC: 0.74\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96     19576\n",
      "           1       0.08      0.21      0.11       424\n",
      "\n",
      "    accuracy                           0.93     20000\n",
      "   macro avg       0.53      0.58      0.54     20000\n",
      "weighted avg       0.96      0.93      0.95     20000\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "                       feature  importance\n",
      "20  user_past_purchases_scaled    0.403396\n",
      "19           version_purchases    0.223688\n",
      "3              user_country_FR    0.078351\n",
      "1                email_version    0.060169\n",
      "2              user_country_ES    0.055880\n",
      "17          version_country_US    0.048318\n",
      "6               weekday_Friday    0.024215\n",
      "9               weekday_Sunday    0.015253\n",
      "18          version_country_UK    0.013468\n",
      "5              user_country_US    0.013302\n",
      "4              user_country_UK    0.012183\n",
      "16              hour_bin_Night    0.010665\n",
      "8             weekday_Saturday    0.006825\n",
      "15            hour_bin_Morning    0.006200\n",
      "12           weekday_Wednesday    0.005216\n",
      "13          hour_bin_Afternoon    0.005195\n",
      "11             weekday_Tuesday    0.003721\n",
      "0                   email_text    0.003633\n",
      "7               weekday_Monday    0.003629\n",
      "10            weekday_Thursday    0.003421\n",
      "14            hour_bin_Evening    0.003272\n",
      "\n",
      "CTR Estimation:\n",
      "Baseline CTR: 2.12%\n",
      "Model CTR (F1-Optimal Threshold 0.709, top 1110 users): 7.93%\n",
      "CTR Improvement (F1-Optimal): 5.81%\n",
      "Model CTR (80th Percentile Threshold 0.550, top 4001 users): 4.97%\n",
      "CTR Improvement (80th Percentile): 2.85%\n",
      "Testing Method: Conduct A/B testing by sending emails to a model-targeted group (high-probability users) and a random group, then compare CTRs.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, precision_recall_curve, f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from scipy.stats import chi2_contingency\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Function to plot bar charts\n",
    "def plot_bar(feature, target, data, save=True):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=feature, y=target, data=data)\n",
    "    plt.title(f'{target.capitalize()} Rate by {feature.capitalize()}')\n",
    "    plt.xticks(rotation=45)\n",
    "    if save:\n",
    "        plt.savefig(f'{target}_by_{feature}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Load data with error handling\n",
    "try:\n",
    "    email_opened = pd.read_csv(\"email_opened_table.csv\")\n",
    "    email_table = pd.read_csv(\"email_table.csv\")\n",
    "    link_clicked = pd.read_csv(\"link_clicked_table.csv\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}. Please ensure CSV files are in the working directory.\")\n",
    "    exit(1)\n",
    "\n",
    "# Data validation\n",
    "if not email_opened['email_id'].isin(email_table['email_id']).all():\n",
    "    print(\"Warning: Some email_ids in email_opened_table not found in email_table\")\n",
    "if not link_clicked['email_id'].isin(email_table['email_id']).all():\n",
    "    print(\"Warning: Some email_ids in link_clicked_table not found in email_table\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in email_table:\\n\", email_table.isnull().sum())\n",
    "print(\"\\nMissing values in email_opened:\\n\", email_opened.isnull().sum())\n",
    "print(\"\\nMissing values in link_clicked:\\n\", link_clicked.isnull().sum())\n",
    "\n",
    "# Add opened and clicked columns\n",
    "email_table['opened'] = email_table['email_id'].isin(email_opened['email_id']).astype(int)\n",
    "email_table['clicked'] = email_table['email_id'].isin(link_clicked['email_id']).astype(int)\n",
    "\n",
    "# Requirement 1: Calculate Open Rate and Click-Through Rate\n",
    "total_emails = len(email_table)\n",
    "emails_opened = email_table['opened'].sum()\n",
    "emails_clicked = email_table['clicked'].sum()\n",
    "open_rate = (emails_opened / total_emails) * 100\n",
    "ctr = (emails_clicked / total_emails) * 100\n",
    "\n",
    "print(f\"\\nTotal Emails Sent: {total_emails}\")\n",
    "print(f\"Emails Opened: {emails_opened}\")\n",
    "print(f\"Emails Clicked: {emails_clicked}\")\n",
    "print(f\"Open Rate: {open_rate:.2f}%\")\n",
    "print(f\"Click-Through Rate: {ctr:.2f}%\")\n",
    "\n",
    "# Requirement 4: Identify Patterns (Exploratory Data Analysis)\n",
    "# Plot open and click rates\n",
    "features_to_plot = ['email_text', 'email_version', 'user_country', 'weekday', 'user_past_purchases']\n",
    "for feature in features_to_plot:\n",
    "    plot_bar(feature, 'opened', email_table)\n",
    "    plot_bar(feature, 'clicked', email_table)\n",
    "\n",
    "# Ensure hour is integer and plot\n",
    "email_table['hour'] = email_table['hour'].astype(int)\n",
    "plot_bar('hour', 'opened', email_table)\n",
    "plot_bar('hour', 'clicked', email_table)\n",
    "\n",
    "# Summarize click rates by segment\n",
    "print(\"\\nClick Rate by Segment:\")\n",
    "for feature in features_to_plot + ['hour']:\n",
    "    print(f\"\\n{feature}:\")\n",
    "    print(email_table.groupby(feature)['clicked'].mean() * 100)\n",
    "\n",
    "# Analyze interactions\n",
    "pivot = email_table.pivot_table(values='clicked', index='email_version', columns='user_country', aggfunc='mean') * 100\n",
    "print(\"\\nClick Rate by Email Version and Country:\")\n",
    "print(pivot)\n",
    "\n",
    "# Statistical test for significance (e.g., email_version vs. clicked)\n",
    "contingency_table = pd.crosstab(email_table['email_version'], email_table['clicked'])\n",
    "chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "print(f\"\\nChi-Square Test (email_version vs. clicked): p-value = {p:.4f}\")\n",
    "\n",
    "# Key patterns (specific values from output)\n",
    "print(\"\\nKey Patterns (Based on Data Analysis):\")\n",
    "print(\"- Short emails had a 2.39% click rate, compared to 1.85% for long emails.\")\n",
    "print(\"- Personalized emails had a 2.73% click rate, significantly higher than 1.51% for generic emails (p < 0.0001).\")\n",
    "print(\"- Users in the US (2.44%) and UK (2.47%) had higher click rates than those in ES (0.83%) and FR (0.80%).\")\n",
    "print(\"- Users with 5+ past purchases had click rates above 3%, with 15 purchases at 11.70% and 19 at 20.00%.\")\n",
    "print(\"- Emails sent on Wednesdays (2.76%) and in the morning (9-11 AM: 2.58-2.82%) had the highest click rates.\")\n",
    "\n",
    "# Requirement 2: Build Machine Learning Model\n",
    "# Preprocess data\n",
    "label_encoder_text = LabelEncoder()\n",
    "email_table['email_text'] = label_encoder_text.fit_transform(email_table['email_text'])\n",
    "label_encoder_version = LabelEncoder()\n",
    "email_table['email_version'] = label_encoder_version.fit_transform(email_table['email_version'])\n",
    "\n",
    "# One-hot encode user_country\n",
    "onehot_encoder_country = OneHotEncoder(sparse_output=False)\n",
    "country_encoded = onehot_encoder_country.fit_transform(email_table[['user_country']])\n",
    "country_encoded_df = pd.DataFrame(\n",
    "    country_encoded,\n",
    "    columns=onehot_encoder_country.get_feature_names_out(['user_country'])\n",
    ").astype(int)\n",
    "email_table = pd.concat([email_table.drop(['user_country'], axis=1), country_encoded_df], axis=1)\n",
    "\n",
    "# One-hot encode weekday\n",
    "onehot_encoder_weekday = OneHotEncoder(sparse_output=False)\n",
    "weekday_encoded = onehot_encoder_weekday.fit_transform(email_table[['weekday']])\n",
    "weekday_encoded_df = pd.DataFrame(\n",
    "    weekday_encoded,\n",
    "    columns=onehot_encoder_weekday.get_feature_names_out(['weekday'])\n",
    ").astype(int)\n",
    "email_table = pd.concat([email_table.drop(['weekday'], axis=1), weekday_encoded_df], axis=1)\n",
    "\n",
    "# Create and encode hour_bin\n",
    "email_table['hour_bin'] = pd.cut(\n",
    "    email_table['hour'],\n",
    "    bins=[0, 6, 12, 18, 24],\n",
    "    labels=['Night', 'Morning', 'Afternoon', 'Evening'],\n",
    "    include_lowest=True\n",
    ")\n",
    "plot_bar('hour_bin', 'opened', email_table)\n",
    "plot_bar('hour_bin', 'clicked', email_table)\n",
    "\n",
    "onehot_encoder_hour_bin = OneHotEncoder(sparse_output=False)\n",
    "hour_bin_encoded = onehot_encoder_hour_bin.fit_transform(email_table[['hour_bin']])\n",
    "hour_bin_encoded_df = pd.DataFrame(\n",
    "    hour_bin_encoded,\n",
    "    columns=onehot_encoder_hour_bin.get_feature_names_out(['hour_bin'])\n",
    ").astype(int)\n",
    "email_table = pd.concat([email_table.drop(['hour', 'hour_bin'], axis=1), hour_bin_encoded_df], axis=1)\n",
    "\n",
    "# Feature engineering: Add interaction terms\n",
    "email_table['version_country_US'] = email_table['email_version'] * email_table['user_country_US']\n",
    "email_table['version_country_UK'] = email_table['email_version'] * email_table['user_country_UK']\n",
    "email_table['version_purchases'] = email_table['email_version'] * email_table['user_past_purchases']\n",
    "\n",
    "# Scale user_past_purchases\n",
    "scaler = StandardScaler()\n",
    "email_table['user_past_purchases_scaled'] = scaler.fit_transform(email_table[['user_past_purchases']])\n",
    "\n",
    "# Prepare features and target\n",
    "X = email_table.drop(['email_id', 'opened', 'clicked', 'user_past_purchases'], axis=1)  # Use scaled purchases\n",
    "y = email_table['clicked']\n",
    "\n",
    "# Check class imbalance\n",
    "print(\"\\nClass Imbalance in Target (clicked):\")\n",
    "class_counts = pd.Series(y).value_counts()\n",
    "class_percentages = pd.Series(y).value_counts(normalize=True) * 100\n",
    "print(pd.DataFrame({\n",
    "    'Class': class_counts.index,\n",
    "    'Count': class_counts.values,\n",
    "    'Percentage': class_percentages.values\n",
    "}))\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Define balancing pipeline (Random Undersampling + SMOTE)\n",
    "resampler = Pipeline([\n",
    "    ('undersample', RandomUnderSampler(sampling_strategy=0.5, random_state=42)),  # Reduce non-clicks\n",
    "    ('smote', SMOTE(sampling_strategy=1.0, random_state=42))  # Balance clicks\n",
    "])\n",
    "X_train_balanced, y_train_balanced = resampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train XGBoost model\n",
    "xgboost_model = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=3,  # Further reduced\n",
    "    eval_metric='aucpr',\n",
    "    random_state=42\n",
    ")\n",
    "xgboost_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Train Balanced Random Forest as alternative\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predict and evaluate (XGBoost)\n",
    "y_prob_xgb = xgboost_model.predict_proba(X_test)[:, 1]\n",
    "precision_xgb, recall_xgb, thresholds_xgb = precision_recall_curve(y_test, y_prob_xgb)\n",
    "f1_scores_xgb = 2 * (precision_xgb * recall_xgb) / (precision_xgb + recall_xgb + 1e-10)\n",
    "optimal_idx_xgb = np.argmax(f1_scores_xgb)\n",
    "optimal_threshold_xgb = thresholds_xgb[optimal_idx_xgb]\n",
    "\n",
    "# Predict and evaluate (Random Forest)\n",
    "y_prob_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "precision_rf, recall_rf, thresholds_rf = precision_recall_curve(y_test, y_prob_rf)\n",
    "f1_scores_rf = 2 * (precision_rf * recall_rf) / (precision_rf + recall_rf + 1e-10)\n",
    "optimal_idx_rf = np.argmax(f1_scores_rf)\n",
    "optimal_threshold_rf = thresholds_rf[optimal_idx_rf]\n",
    "\n",
    "# Select best model based on F1-score\n",
    "y_pred_xgb = (y_prob_xgb >= optimal_threshold_xgb).astype(int)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "y_pred_rf = (y_prob_rf >= optimal_threshold_rf).astype(int)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "best_model = xgboost_model if f1_xgb >= f1_rf else rf_model\n",
    "best_threshold = optimal_threshold_xgb if f1_xgb >= f1_rf else optimal_threshold_rf\n",
    "best_y_prob = y_prob_xgb if f1_xgb >= f1_rf else y_prob_rf\n",
    "best_model_name = \"XGBoost\" if f1_xgb >= f1_rf else \"Balanced Random Forest\"\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"F1-Optimal Threshold: {best_threshold:.3f}\")\n",
    "\n",
    "# Evaluate best model\n",
    "y_pred = (best_y_prob >= best_threshold).astype(int)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, best_y_prob)\n",
    "cv_auc = cross_val_score(best_model, X, y, cv=5, scoring='roc_auc').mean()\n",
    "\n",
    "print(f\"\\nModel Performance (F1-Optimal Threshold):\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"AUC-ROC: {auc:.2f}\")\n",
    "print(f\"Cross-Validated AUC-ROC: {cv_auc:.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Precision-Recall Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall_xgb, precision_xgb, label='XGBoost', marker='.')\n",
    "plt.plot(recall_rf, precision_rf, label='Random Forest', marker='.')\n",
    "plt.axvline(x=recall_xgb[optimal_idx_xgb] if f1_xgb >= f1_rf else recall_rf[optimal_idx_rf], \n",
    "            color='r', linestyle='--', label=f'F1-Optimal Threshold ({best_threshold:.3f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.savefig('precision_recall_curve.png')\n",
    "plt.close()\n",
    "\n",
    "# Feature importance\n",
    "importances = pd.DataFrame({'feature': X.columns, 'importance': best_model.feature_importances_})\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(importances.sort_values(by='importance', ascending=False))\n",
    "\n",
    "# Requirement 3: Estimate CTR Improvement\n",
    "N = int(0.2 * len(email_table))  # 20,000 emails\n",
    "test_results = pd.DataFrame({'prob': best_y_prob, 'clicked': y_test, 'index': X_test.index})\n",
    "high_prob_users = test_results[test_results['prob'] >= best_threshold]\n",
    "top_n = high_prob_users.head(N) if len(high_prob_users) >= N else high_prob_users  # Ensure enough users\n",
    "new_ctr_optimal = top_n['clicked'].mean() * 100 if not top_n.empty else 0.0\n",
    "\n",
    "threshold_80 = np.percentile(test_results['prob'], 80)\n",
    "high_prob_users_80 = test_results[test_results['prob'] >= threshold_80]\n",
    "top_n_80 = high_prob_users_80.head(N) if len(high_prob_users_80) >= N else high_prob_users_80\n",
    "new_ctr_80 = top_n_80['clicked'].mean() * 100 if not top_n_80.empty else 0.0\n",
    "\n",
    "print(f\"\\nCTR Estimation:\")\n",
    "print(f\"Baseline CTR: {ctr:.2f}%\")\n",
    "print(f\"Model CTR (F1-Optimal Threshold {best_threshold:.3f}, top {len(top_n)} users): {new_ctr_optimal:.2f}%\")\n",
    "print(f\"CTR Improvement (F1-Optimal): {new_ctr_optimal - ctr:.2f}%\")\n",
    "print(f\"Model CTR (80th Percentile Threshold {threshold_80:.3f}, top {len(top_n_80)} users): {new_ctr_80:.2f}%\")\n",
    "print(f\"CTR Improvement (80th Percentile): {new_ctr_80 - ctr:.2f}%\")\n",
    "print(\"Testing Method: Conduct A/B testing by sending emails to a model-targeted group (high-probability users) and a random group, then compare CTRs.\")\n",
    "\n",
    "# Save predictions and results\n",
    "test_results.to_csv('model_predictions.csv', index=False)\n",
    "email_table.to_csv('processed_email_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2659b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0010e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c901f664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e9cc74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ea59d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in email_table:\n",
      " email_id               0\n",
      "email_text             0\n",
      "email_version          0\n",
      "hour                   0\n",
      "weekday                0\n",
      "user_country           0\n",
      "user_past_purchases    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in email_opened:\n",
      " email_id    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in link_clicked:\n",
      " email_id    0\n",
      "dtype: int64\n",
      "\n",
      "Total Emails Sent: 100000\n",
      "Emails Opened: 10345\n",
      "Emails Clicked: 2119\n",
      "Open Rate: 10.35%\n",
      "Click-Through Rate: 2.12%\n",
      "\n",
      "Click Rate by Segment:\n",
      "\n",
      "email_text:\n",
      "email_text\n",
      "long_email     1.853767\n",
      "short_email    2.387177\n",
      "Name: clicked, dtype: float64\n",
      "\n",
      "email_version:\n",
      "email_version\n",
      "generic         1.513673\n",
      "personalized    2.729409\n",
      "Name: clicked, dtype: float64\n",
      "\n",
      "user_country:\n",
      "user_country\n",
      "ES    0.832748\n",
      "FR    0.800400\n",
      "UK    2.467526\n",
      "US    2.435981\n",
      "Name: clicked, dtype: float64\n",
      "\n",
      "weekday:\n",
      "weekday\n",
      "Friday       1.403682\n",
      "Monday       2.290608\n",
      "Saturday     1.784611\n",
      "Sunday       1.675123\n",
      "Thursday     2.444491\n",
      "Tuesday      2.488864\n",
      "Wednesday    2.761999\n",
      "Name: clicked, dtype: float64\n",
      "\n",
      "user_past_purchases:\n",
      "user_past_purchases\n",
      "0       0.050443\n",
      "1       1.119919\n",
      "2       1.534213\n",
      "3       1.656040\n",
      "4       2.140929\n",
      "5       2.222960\n",
      "6       3.205640\n",
      "7       3.073872\n",
      "8       3.960847\n",
      "9       4.550971\n",
      "10      4.655099\n",
      "11      5.602061\n",
      "12      6.567797\n",
      "13      6.574394\n",
      "14      9.116022\n",
      "15     11.702128\n",
      "16     11.764706\n",
      "17      8.333333\n",
      "18      2.857143\n",
      "19     20.000000\n",
      "20      0.000000\n",
      "21     50.000000\n",
      "22    100.000000\n",
      "Name: clicked, dtype: float64\n",
      "\n",
      "hour:\n",
      "hour\n",
      "1     1.812801\n",
      "2     1.632209\n",
      "3     1.952278\n",
      "4     1.618641\n",
      "5     1.801252\n",
      "6     1.714668\n",
      "7     1.828376\n",
      "8     1.893308\n",
      "9     2.579435\n",
      "10    2.823961\n",
      "11    2.712816\n",
      "12    2.566073\n",
      "13    1.988891\n",
      "14    2.074236\n",
      "15    2.490696\n",
      "16    2.319681\n",
      "17    1.848917\n",
      "18    1.618578\n",
      "19    1.657459\n",
      "20    1.219512\n",
      "21    0.821918\n",
      "22    1.960784\n",
      "23    4.137931\n",
      "24    2.898551\n",
      "Name: clicked, dtype: float64\n",
      "\n",
      "Click Rate by Email Version and Country:\n",
      "user_country         ES        FR        UK        US\n",
      "email_version                                        \n",
      "generic        0.562588  0.536459  1.826209  1.729898\n",
      "personalized   1.102204  1.068118  3.108393  3.150740\n",
      "\n",
      "Chi-Square Test (email_version vs. clicked): p-value = 0.0000\n",
      "\n",
      "Key Patterns (Based on Data Analysis):\n",
      "- Short emails had a 2.39% click rate, compared to 1.85% for long emails.\n",
      "- Personalized emails had a 2.73% click rate, significantly higher than 1.51% for generic emails (p < 0.0001).\n",
      "- Users in the US (2.44%) and UK (2.47%) had higher click rates than those in ES (0.83%) and FR (0.80%).\n",
      "- Users with 5+ past purchases had click rates above 3%, with 15 purchases at 11.70% and 19 at 20.00%.\n",
      "- Emails sent on Wednesdays (2.76%) and in the morning (9-11 AM: 2.58-2.82%) had the highest click rates.\n",
      "\n",
      "Selected Features: ['email_text', 'email_version', 'user_country_ES', 'user_country_FR', 'user_country_UK', 'user_country_US', 'weekday_Friday', 'weekday_Sunday', 'weekday_Wednesday', 'hour_bin_Morning', 'hour_bin_Night', 'version_country_US', 'version_country_UK', 'version_purchases', 'user_past_purchases_scaled']\n",
      "\n",
      "Class Imbalance in Target (clicked):\n",
      "   Class  Count  Percentage\n",
      "0      0  97881      97.881\n",
      "1      1   2119       2.119\n"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'sampling_strategy' parameter of RandomUnderSampler must be a float in the range (0.0, 1.0], a str among {'not minority', 'not majority', 'auto', 'all', 'majority'}, an instance of 'collections.abc.Mapping' or a callable. Got 4.0 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidParameterError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 182\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# Define balancing pipeline (Random Undersampling + SMOTE)\u001b[39;00m\n\u001b[32m    178\u001b[39m resampler = Pipeline([\n\u001b[32m    179\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mundersample\u001b[39m\u001b[33m'\u001b[39m, RandomUnderSampler(sampling_strategy=\u001b[32m4.0\u001b[39m, random_state=\u001b[32m42\u001b[39m)),  \u001b[38;5;66;03m# 4:1 ratio\u001b[39;00m\n\u001b[32m    180\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33msmote\u001b[39m\u001b[33m'\u001b[39m, SMOTE(sampling_strategy=\u001b[32m1.0\u001b[39m, random_state=\u001b[32m42\u001b[39m))  \u001b[38;5;66;03m# 1:1 final ratio\u001b[39;00m\n\u001b[32m    181\u001b[39m ])\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m X_train_balanced, y_train_balanced = \u001b[43mresampler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# Train Balanced Random Forest\u001b[39;00m\n\u001b[32m    185\u001b[39m model = RandomForestClassifier(\n\u001b[32m    186\u001b[39m     n_estimators=\u001b[32m200\u001b[39m,\n\u001b[32m    187\u001b[39m     max_depth=\u001b[32m5\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    190\u001b[39m     random_state=\u001b[32m42\u001b[39m\n\u001b[32m    191\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\internship-assignment\\myenv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\internship-assignment\\myenv\\Lib\\site-packages\\imblearn\\pipeline.py:726\u001b[39m, in \u001b[36mPipeline.fit_resample\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    680\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Fit the model and sample with the final estimator.\u001b[39;00m\n\u001b[32m    681\u001b[39m \n\u001b[32m    682\u001b[39m \u001b[33;03mFits all the transformers/samplers one after the other and\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    723\u001b[39m \u001b[33;03m    Transformed target.\u001b[39;00m\n\u001b[32m    724\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    725\u001b[39m routed_params = \u001b[38;5;28mself\u001b[39m._check_method_params(method=\u001b[33m\"\u001b[39m\u001b[33mfit_resample\u001b[39m\u001b[33m\"\u001b[39m, props=params)\n\u001b[32m--> \u001b[39m\u001b[32m726\u001b[39m Xt, yt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    727\u001b[39m last_step = \u001b[38;5;28mself\u001b[39m._final_estimator\n\u001b[32m    728\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps) - \u001b[32m1\u001b[39m)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\internship-assignment\\myenv\\Lib\\site-packages\\imblearn\\pipeline.py:440\u001b[39m, in \u001b[36mPipeline._fit\u001b[39m\u001b[34m(self, X, y, routed_params, raw_params)\u001b[39m\n\u001b[32m    430\u001b[39m     X, fitted_transformer = fit_transform_one_cached(\n\u001b[32m    431\u001b[39m         cloned_transformer,\n\u001b[32m    432\u001b[39m         X,\n\u001b[32m   (...)\u001b[39m\u001b[32m    437\u001b[39m         params=step_params,\n\u001b[32m    438\u001b[39m     )\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(cloned_transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_resample\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m     X, y, fitted_transformer = \u001b[43mfit_resample_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPipeline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    446\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[32m    449\u001b[39m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[32m    450\u001b[39m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m.steps[step_idx] = (name, fitted_transformer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\internship-assignment\\myenv\\Lib\\site-packages\\joblib\\memory.py:312\u001b[39m, in \u001b[36mNotMemorizedFunc.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\internship-assignment\\myenv\\Lib\\site-packages\\imblearn\\pipeline.py:1336\u001b[39m, in \u001b[36m_fit_resample_one\u001b[39m\u001b[34m(sampler, X, y, message_clsname, message, params)\u001b[39m\n\u001b[32m   1334\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_fit_resample_one\u001b[39m(sampler, X, y, message_clsname=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, message=\u001b[38;5;28;01mNone\u001b[39;00m, params=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1335\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m         X_res, y_res = \u001b[43msampler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_resample\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1338\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m X_res, y_res, sampler\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\internship-assignment\\myenv\\Lib\\site-packages\\imblearn\\base.py:202\u001b[39m, in \u001b[36mBaseSampler.fit_resample\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit_resample\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, **params):\n\u001b[32m    182\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[32m    183\u001b[39m \n\u001b[32m    184\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    200\u001b[39m \u001b[33;03m        The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\internship-assignment\\myenv\\Lib\\site-packages\\sklearn\\base.py:1382\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1377\u001b[39m partial_fit_and_fitted = (\n\u001b[32m   1378\u001b[39m     fit_method.\u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33mpartial_fit\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[32m   1379\u001b[39m )\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[32m-> \u001b[39m\u001b[32m1382\u001b[39m     \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m   1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\internship-assignment\\myenv\\Lib\\site-packages\\sklearn\\base.py:436\u001b[39m, in \u001b[36mBaseEstimator._validate_params\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    429\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[32m    430\u001b[39m \n\u001b[32m    431\u001b[39m \u001b[33;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    434\u001b[39m \u001b[33;03m    accepted constraints.\u001b[39;00m\n\u001b[32m    435\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m436\u001b[39m     \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\internship-assignment\\myenv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:98\u001b[39m, in \u001b[36mvalidate_parameter_constraints\u001b[39m\u001b[34m(parameter_constraints, params, caller_name)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     93\u001b[39m     constraints_str = (\n\u001b[32m     94\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:-\u001b[32m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m or\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[-\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     96\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[32m     99\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    101\u001b[39m )\n",
      "\u001b[31mInvalidParameterError\u001b[39m: The 'sampling_strategy' parameter of RandomUnderSampler must be a float in the range (0.0, 1.0], a str among {'not minority', 'not majority', 'auto', 'all', 'majority'}, an instance of 'collections.abc.Mapping' or a callable. Got 4.0 instead."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, precision_recall_curve, f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import uuid\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Function to plot bar charts\n",
    "def plot_bar(feature, target, data, save=True):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=feature, y=target, data=data)\n",
    "    plt.title(f'{target.capitalize()} Rate by {feature.capitalize()}')\n",
    "    plt.xticks(rotation=45)\n",
    "    if save:\n",
    "        plt.savefig(f'{target}_by_{feature}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Load data with error handling\n",
    "try:\n",
    "    email_opened = pd.read_csv(\"email_opened_table.csv\")\n",
    "    email_table = pd.read_csv(\"email_table.csv\")\n",
    "    link_clicked = pd.read_csv(\"link_clicked_table.csv\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}. Please ensure CSV files are in the working directory.\")\n",
    "    exit(1)\n",
    "\n",
    "# Data validation\n",
    "if not email_opened['email_id'].isin(email_table['email_id']).all():\n",
    "    print(\"Warning: Some email_ids in email_opened_table not found in email_table\")\n",
    "if not link_clicked['email_id'].isin(email_table['email_id']).all():\n",
    "    print(\"Warning: Some email_ids in link_clicked_table not found in email_table\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in email_table:\\n\", email_table.isnull().sum())\n",
    "print(\"\\nMissing values in email_opened:\\n\", email_opened.isnull().sum())\n",
    "print(\"\\nMissing values in link_clicked:\\n\", link_clicked.isnull().sum())\n",
    "\n",
    "# Add opened and clicked columns\n",
    "email_table['opened'] = email_table['email_id'].isin(email_opened['email_id']).astype(int)\n",
    "email_table['clicked'] = email_table['email_id'].isin(link_clicked['email_id']).astype(int)\n",
    "\n",
    "# Requirement 1: Calculate Open Rate and Click-Through Rate\n",
    "total_emails = len(email_table)\n",
    "emails_opened = email_table['opened'].sum()\n",
    "emails_clicked = email_table['clicked'].sum()\n",
    "open_rate = (emails_opened / total_emails) * 100\n",
    "ctr = (emails_clicked / total_emails) * 100\n",
    "\n",
    "print(f\"\\nTotal Emails Sent: {total_emails}\")\n",
    "print(f\"Emails Opened: {emails_opened}\")\n",
    "print(f\"Emails Clicked: {emails_clicked}\")\n",
    "print(f\"Open Rate: {open_rate:.2f}%\")\n",
    "print(f\"Click-Through Rate: {ctr:.2f}%\")\n",
    "\n",
    "# Requirement 4: Identify Patterns (Exploratory Data Analysis)\n",
    "# Plot open and click rates\n",
    "features_to_plot = ['email_text', 'email_version', 'user_country', 'weekday', 'user_past_purchases']\n",
    "for feature in features_to_plot:\n",
    "    plot_bar(feature, 'opened', email_table)\n",
    "    plot_bar(feature, 'clicked', email_table)\n",
    "\n",
    "# Ensure hour is integer and plot\n",
    "email_table['hour'] = email_table['hour'].astype(int)\n",
    "plot_bar('hour', 'opened', email_table)\n",
    "plot_bar('hour', 'clicked', email_table)\n",
    "\n",
    "# Summarize click rates by segment\n",
    "print(\"\\nClick Rate by Segment:\")\n",
    "for feature in features_to_plot + ['hour']:\n",
    "    print(f\"\\n{feature}:\")\n",
    "    print(email_table.groupby(feature)['clicked'].mean() * 100)\n",
    "\n",
    "# Analyze interactions\n",
    "pivot = email_table.pivot_table(values='clicked', index='email_version', columns='user_country', aggfunc='mean') * 100\n",
    "print(\"\\nClick Rate by Email Version and Country:\")\n",
    "print(pivot)\n",
    "\n",
    "# Statistical test for significance (e.g., email_version vs. clicked)\n",
    "contingency_table = pd.crosstab(email_table['email_version'], email_table['clicked'])\n",
    "chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "print(f\"\\nChi-Square Test (email_version vs. clicked): p-value = {p:.4f}\")\n",
    "\n",
    "# Key patterns (specific values from output)\n",
    "print(\"\\nKey Patterns (Based on Data Analysis):\")\n",
    "print(\"- Short emails had a 2.39% click rate, compared to 1.85% for long emails.\")\n",
    "print(\"- Personalized emails had a 2.73% click rate, significantly higher than 1.51% for generic emails (p < 0.0001).\")\n",
    "print(\"- Users in the US (2.44%) and UK (2.47%) had higher click rates than those in ES (0.83%) and FR (0.80%).\")\n",
    "print(\"- Users with 5+ past purchases had click rates above 3%, with 15 purchases at 11.70% and 19 at 20.00%.\")\n",
    "print(\"- Emails sent on Wednesdays (2.76%) and in the morning (9-11 AM: 2.58-2.82%) had the highest click rates.\")\n",
    "\n",
    "# Requirement 2: Build Machine Learning Model\n",
    "# Preprocess data\n",
    "label_encoder_text = LabelEncoder()\n",
    "email_table['email_text'] = label_encoder_text.fit_transform(email_table['email_text'])\n",
    "label_encoder_version = LabelEncoder()\n",
    "email_table['email_version'] = label_encoder_version.fit_transform(email_table['email_version'])\n",
    "\n",
    "# One-hot encode user_country\n",
    "onehot_encoder_country = OneHotEncoder(sparse_output=False)\n",
    "country_encoded = onehot_encoder_country.fit_transform(email_table[['user_country']])\n",
    "country_encoded_df = pd.DataFrame(\n",
    "    country_encoded,\n",
    "    columns=onehot_encoder_country.get_feature_names_out(['user_country'])\n",
    ").astype(int)\n",
    "email_table = pd.concat([email_table.drop(['user_country'], axis=1), country_encoded_df], axis=1)\n",
    "\n",
    "# One-hot encode weekday\n",
    "onehot_encoder_weekday = OneHotEncoder(sparse_output=False)\n",
    "weekday_encoded = onehot_encoder_weekday.fit_transform(email_table[['weekday']])\n",
    "weekday_encoded_df = pd.DataFrame(\n",
    "    weekday_encoded,\n",
    "    columns=onehot_encoder_weekday.get_feature_names_out(['weekday'])\n",
    ").astype(int)\n",
    "email_table = pd.concat([email_table.drop(['weekday'], axis=1), weekday_encoded_df], axis=1)\n",
    "\n",
    "# Create and encode hour_bin\n",
    "email_table['hour_bin'] = pd.cut(\n",
    "    email_table['hour'],\n",
    "    bins=[0, 6, 12, 18, 24],\n",
    "    labels=['Night', 'Morning', 'Afternoon', 'Evening'],\n",
    "    include_lowest=True\n",
    ")\n",
    "plot_bar('hour_bin', 'opened', email_table)\n",
    "plot_bar('hour_bin', 'clicked', email_table)\n",
    "\n",
    "onehot_encoder_hour_bin = OneHotEncoder(sparse_output=False)\n",
    "hour_bin_encoded = onehot_encoder_hour_bin.fit_transform(email_table[['hour_bin']])\n",
    "hour_bin_encoded_df = pd.DataFrame(\n",
    "    hour_bin_encoded,\n",
    "    columns=onehot_encoder_hour_bin.get_feature_names_out(['hour_bin'])\n",
    ").astype(int)\n",
    "email_table = pd.concat([email_table.drop(['hour', 'hour_bin'], axis=1), hour_bin_encoded_df], axis=1)\n",
    "\n",
    "# Feature engineering: Add interaction terms\n",
    "email_table['version_country_US'] = email_table['email_version'] * email_table['user_country_US']\n",
    "email_table['version_country_UK'] = email_table['email_version'] * email_table['user_country_UK']\n",
    "email_table['version_purchases'] = email_table['email_version'] * email_table['user_past_purchases']\n",
    "\n",
    "# Scale user_past_purchases\n",
    "scaler = StandardScaler()\n",
    "email_table['user_past_purchases_scaled'] = scaler.fit_transform(email_table[['user_past_purchases']])\n",
    "\n",
    "# Prepare features and target\n",
    "X = email_table.drop(['email_id', 'opened', 'clicked', 'user_past_purchases'], axis=1)\n",
    "y = email_table['clicked']\n",
    "\n",
    "# Feature selection to reduce overreliance on purchase features\n",
    "selector = SelectKBest(score_func=f_classif, k=15)\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "selected_features = X.columns[selector.get_support()].tolist()\n",
    "print(\"\\nSelected Features:\", selected_features)\n",
    "X = pd.DataFrame(X_selected, columns=selected_features, index=X.index)\n",
    "\n",
    "# Check class imbalance\n",
    "print(\"\\nClass Imbalance in Target (clicked):\")\n",
    "class_counts = pd.Series(y).value_counts()\n",
    "class_percentages = pd.Series(y).value_counts(normalize=True) * 100\n",
    "print(pd.DataFrame({\n",
    "    'Class': class_counts.index,\n",
    "    'Count': class_counts.values,\n",
    "    'Percentage': class_percentages.values\n",
    "}))\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Define balancing pipeline (Random Undersampling + SMOTE)\n",
    "resampler = Pipeline([\n",
    "    ('undersample', RandomUnderSampler(sampling_strategy=4.0, random_state=42)),  # 4:1 ratio\n",
    "    ('smote', SMOTE(sampling_strategy=1.0, random_state=42))  # 1:1 final ratio\n",
    "])\n",
    "X_train_balanced, y_train_balanced = resampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train Balanced Random Forest\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    min_samples_split=20,  # Increase to reduce overfitting\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "optimal_idx = np.argmax(f1_scores)\n",
    "f1_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# Find CTR-optimized threshold (maximize CTR with at least 10,000 users)\n",
    "test_results = pd.DataFrame({'prob': y_prob, 'clicked': y_test, 'index': X_test.index})\n",
    "N = int(0.2 * len(email_table))  # 20,000 users\n",
    "min_users = 10000\n",
    "ctr_scores = []\n",
    "for t in thresholds:\n",
    "    high_prob_users = test_results[test_results['prob'] >= t]\n",
    "    if len(high_prob_users) >= min_users:\n",
    "        top_n = high_prob_users.head(N) if len(high_prob_users) >= N else high_prob_users\n",
    "        ctr_score = top_n['clicked'].mean() * 100 if not top_n.empty else 0.0\n",
    "        ctr_scores.append((t, ctr_score, len(top_n)))\n",
    "ctr_scores = sorted(ctr_scores, key=lambda x: x[1], reverse=True)\n",
    "ctr_threshold = ctr_scores[0][0] if ctr_scores else f1_threshold\n",
    "ctr_users = ctr_scores[0][2] if ctr_scores else len(test_results[test_results['prob'] >= f1_threshold])\n",
    "new_ctr_optimal = ctr_scores[0][1] if ctr_scores else test_results[test_results['prob'] >= f1_threshold]['clicked'].mean() * 100\n",
    "\n",
    "print(f\"\\nF1-Optimal Threshold: {f1_threshold:.3f}\")\n",
    "print(f\"CTR-Optimized Threshold: {ctr_threshold:.3f}\")\n",
    "\n",
    "# Evaluate with F1-optimal threshold\n",
    "y_pred = (y_prob >= f1_threshold).astype(int)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "cv_auc = cross_val_score(model, X, y, cv=5, scoring='roc_auc').mean()\n",
    "\n",
    "print(f\"\\nModel Performance (F1-Optimal Threshold):\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"AUC-ROC: {auc:.2f}\")\n",
    "print(f\"Cross-Validated AUC-ROC: {cv_auc:.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Precision-Recall Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.axvline(x=recall[optimal_idx], color='r', linestyle='--', label=f'F1-Optimal Threshold ({f1_threshold:.3f})')\n",
    "plt.axvline(x=ctr_threshold, color='b', linestyle='--', label=f'CTR-Optimized Threshold ({ctr_threshold:.3f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.savefig('precision_recall_curve.png')\n",
    "plt.close()\n",
    "\n",
    "# Feature importance\n",
    "importances = pd.DataFrame({'feature': X.columns, 'importance': model.feature_importances_})\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(importances.sort_values(by='importance', ascending=False))\n",
    "\n",
    "# CTR Estimation\n",
    "high_prob_users_f1 = test_results[test_results['prob'] >= f1_threshold]\n",
    "top_n_f1 = high_prob_users_f1.head(N) if len(high_prob_users_f1) >= N else high_prob_users_f1\n",
    "new_ctr_f1 = top_n_f1['clicked'].mean() * 100 if not top_n_f1.empty else 0.0\n",
    "\n",
    "threshold_80 = np.percentile(test_results['prob'], 80)\n",
    "high_prob_users_80 = test_results[test_results['prob'] >= threshold_80]\n",
    "top_n_80 = high_prob_users_80.head(N) if len(high_prob_users_80) >= N else high_prob_users_80\n",
    "new_ctr_80 = top_n_80['clicked'].mean() * 100 if not top_n_80.empty else 0.0\n",
    "\n",
    "print(f\"\\nCTR Estimation:\")\n",
    "print(f\"Baseline CTR: {ctr:.2f}%\")\n",
    "print(f\"Model CTR (F1-Optimal Threshold {f1_threshold:.3f}, top {len(top_n_f1)} users): {new_ctr_f1:.2f}%\")\n",
    "print(f\"CTR Improvement (F1-Optimal): {new_ctr_f1 - ctr:.2f}%\")\n",
    "print(f\"Model CTR (CTR-Optimal Threshold {ctr_threshold:.3f}, top {ctr_users} users): {new_ctr_optimal:.2f}%\")\n",
    "print(f\"CTR Improvement (CTR-Optimal): {new_ctr_optimal - ctr:.2f}%\")\n",
    "print(f\"Model CTR (80th Percentile Threshold {threshold_80:.3f}, top {len(top_n_80)} users): {new_ctr_80:.2f}%\")\n",
    "print(f\"CTR Improvement (80th Percentile): {new_ctr_80 - ctr:.2f}%\")\n",
    "print(\"Testing Method: Conduct A/B testing by sending emails to a model-targeted group (high-probability users) and a random group, then compare CTRs.\")\n",
    "\n",
    "# Save predictions and results\n",
    "test_results.to_csv('model_predictions.csv', index=False)\n",
    "email_table.to_csv('processed_email_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a220201a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
